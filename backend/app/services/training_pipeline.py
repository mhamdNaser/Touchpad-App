# app/services/training_pipeline.py
import json
import pickle
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from typing import List
from sklearn.preprocessing import LabelEncoder
from sklearn.utils.class_weight import compute_class_weight
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (
    Conv1D, MaxPooling1D, GlobalAveragePooling1D,
    Dense, Dropout, BatchNormalization
)
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam

from app.services.gesture_data_loader import GestureDataLoader
from app.services.features_visualizer import ProductionFeatureExtractor


class TrainingPipeline:
    def __init__(self, max_timesteps: int = 50, verbose: bool = True):
        self.data_loader = GestureDataLoader()
        self.feature_extractor = ProductionFeatureExtractor(max_timesteps=max_timesteps, verbose=verbose)
        self.max_timesteps = max_timesteps
        self.verbose = verbose
        self.label_encoder = LabelEncoder()

    # ======================================================
    # âœ… Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ 1D-CNN Ù…Ø­Ø³Ù‘Ù†
    # ======================================================
    def build_cnn_model(self, input_shape, num_classes):
        model = Sequential([
            Conv1D(32, kernel_size=3, activation='relu', padding='same', input_shape=input_shape),
            BatchNormalization(),
            MaxPooling1D(pool_size=2),
            Dropout(0.5),

            Conv1D(16, kernel_size=3, activation='relu', padding='same'),
            BatchNormalization(),
            GlobalAveragePooling1D(),

            Dense(32, activation='relu'),
            Dropout(0.6),
            Dense(num_classes, activation='softmax')
        ])

        model.compile(
            loss='categorical_crossentropy',
            optimizer=Adam(learning_rate=0.0005),
            metrics=['accuracy']
        )
        
        if self.verbose:
            print(f"âœ… Built CNN model with input shape {input_shape} and {num_classes} classes")
        return model

    # ======================================================
    # ğŸ“Š Ø±Ø³Ù… Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³
    # ======================================================
    def plot_confusion_matrix(self, y_true, y_pred, classes):
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(12, 8))
        sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Blues')
        plt.xlabel('Predicted')
        plt.ylabel('True')
        plt.title('Confusion Matrix')
        plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.show()

    # ======================================================
    # ğŸ“ˆ Ø±Ø³Ù… Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    # ======================================================
    def plot_training_history(self, history):
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # Ø±Ø³Ù… Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚
        ax1.plot(history.history['accuracy'], label='Training Accuracy')
        ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')
        ax1.set_title('Model Accuracy')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Accuracy')
        ax1.legend()
        ax1.grid(True)
        
        # Ø±Ø³Ù… ÙÙ‚Ø¯Ø§Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚
        ax2.plot(history.history['loss'], label='Training Loss')
        ax2.plot(history.history['val_loss'], label='Validation Loss')
        ax2.set_title('Model Loss')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Loss')
        ax2.legend()
        ax2.grid(True)
        
        plt.tight_layout()
        plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
        plt.show()

    # ======================================================
    # ğŸ” ÙØ­Øµ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    # ======================================================
    def _validate_data_quality(self, X_train, X_val, X_test, y_train, y_val, y_test):
        print("\nğŸ” Validating data quality...")

        def check_data_stats(data, name):
            flat_data = data.reshape(-1, data.shape[-1])
            print(f"ğŸ“Š {name} - Shape: {data.shape}")
            print(f"   Range: [{data.min():.4f}, {data.max():.4f}]")
            print(f"   Mean: {data.mean():.4f}, Std: {data.std():.4f}")
            print(f"   NaN: {np.isnan(data).sum()}, Inf: {np.isinf(data).sum()}")
            zero_ratio = (np.abs(flat_data) < 1e-6).mean()
            print(f"   Zero ratio: {zero_ratio:.4f}")
            return zero_ratio

        zero_ratios = [
            check_data_stats(X_train, "X_train"),
            check_data_stats(X_val, "X_val"),
            check_data_stats(X_test, "X_test")
        ]

        print(f"ğŸ¯ Label distribution:")
        for name, y_set in [('Train', y_train), ('Val', y_val), ('Test', y_test)]:
            unique, counts = np.unique(y_set, return_counts=True)
            print(f"   {name}: {dict(zip(unique, counts))}")

        if any(ratio > 0.8 for ratio in zero_ratios):
            print("âš ï¸  WARNING: High zero ratio detected - data might be over-padded")

    # ======================================================
    # ğŸš€ ØªÙ†ÙÙŠØ° Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„ØªØ¯Ø±ÙŠØ¨ 1D-CNN
    # ======================================================
    def train_model(self):
        print("ğŸš€ Starting 1D-CNN training pipeline...")

        # 1ï¸âƒ£ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        gestures_data = self.data_loader.load_all_gestures()
        print(f"âœ… Loaded {len(gestures_data)} gestures")
        if len(gestures_data) == 0:
            raise ValueError("âŒ No gestures loaded from API.")

        # 2ï¸âƒ£ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª sequences per-frame
        X = []
        y = []
        for g in gestures_data:
            seq = self.feature_extractor._gesture_to_sequence(g)
            X.append(seq)
            y.append(g['character'])

        X = np.array(X, dtype=np.float32)
        y = np.array(y)

        # 3ï¸âƒ£ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø­Ø±ÙˆÙ Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù…
        y_encoded = self.label_encoder.fit_transform(y)
        num_classes = len(self.label_encoder.classes_)
        print(f"ğŸ¯ Number of classes: {num_classes}")
        print(f"ğŸ”  Class names: {self.label_encoder.classes_}")

        # 4ï¸âƒ£ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        X_train, X_temp, y_train, y_temp = train_test_split(
            X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42
        )
        X_val, X_test, y_val, y_test = train_test_split(
            X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42
        )

        # 5ï¸âƒ£ ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ one-hot
        y_train_cat = to_categorical(y_train, num_classes=num_classes)
        y_val_cat = to_categorical(y_val, num_classes=num_classes)
        y_test_cat = to_categorical(y_test, num_classes=num_classes)

        # 6ï¸âƒ£ Ø­Ø³Ø§Ø¨ Ø£ÙˆØ²Ø§Ù† Ø§Ù„ÙØ¦Ø§Øª
        try:
            class_weights = compute_class_weight(
                'balanced',
                classes=np.unique(y_train),
                y=y_train
            )
            class_weights = dict(enumerate(class_weights))
            print(f"âš–ï¸ Class weights: {class_weights}")
        except Exception as e:
            print(f"âš ï¸ Could not compute class weights: {e}")
            class_weights = None

        # 7ï¸âƒ£ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        input_shape = (X_train.shape[1], X_train.shape[2])
        model = self.build_cnn_model(input_shape, num_classes)
        model.summary()

        # 8ï¸âƒ£ Callbacks
        early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)
        checkpoint = ModelCheckpoint('arabic_gesture_cnn_best.h5', monitor='val_accuracy', save_best_only=True, verbose=1)
        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-7, verbose=1)

        # 9ï¸âƒ£ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        batch_size = min(32, len(X_train) // 4)
        batch_size = max(batch_size, 8)
        print(f"ğŸ¯ Using batch size: {batch_size}")

        history = model.fit(
            X_train, y_train_cat,
            validation_data=(X_val, y_val_cat),
            epochs=100,
            batch_size=batch_size,
            callbacks=[early_stop, checkpoint, reduce_lr],
            class_weight=class_weights,
            verbose=1
        )

        # 10ï¸âƒ£ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)
        print(f"âœ… Test accuracy: {test_acc:.3f}")
        print(f"âœ… Test loss: {test_loss:.3f}")

        y_pred_proba = model.predict(X_test, verbose=0)
        y_pred = np.argmax(y_pred_proba, axis=1)

        print("\nğŸ“Š Classification report:")
        print(classification_report(y_test, y_pred, target_names=self.label_encoder.classes_, zero_division=0))
        self.plot_confusion_matrix(y_test, y_pred, self.label_encoder.classes_)
        self.plot_training_history(history)

        # 11ï¸âƒ£ Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
        model.save("arabic_gesture_cnn_final.h5", save_format='h5')
        with open("label_encoder.pkl", "wb") as f:
            pickle.dump(self.label_encoder, f)
        with open("X_test.pkl", "wb") as f:
            pickle.dump(X_test, f)
        with open("y_test.pkl", "wb") as f:
            pickle.dump(y_test, f)
        print("ğŸ’¾ Saved model, label encoder, and test data")

        return {
            'model': model,
            'history': history,
            'test_accuracy': float(test_acc),
            'test_loss': float(test_loss),
            'predictions': {
                'y_true': y_test,
                'y_pred': y_pred,
                'y_pred_proba': y_pred_proba
            }
        }