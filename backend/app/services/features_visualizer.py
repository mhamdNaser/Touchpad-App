import numpy as np
import pandas as pd
from typing import List, Dict
from sklearn.preprocessing import RobustScaler, LabelEncoder
from sklearn.model_selection import train_test_split


class FeatureEngineerVisualizer:
    def __init__(self, max_timesteps: int = 150, test_size: float = 0.2, val_size: float = 0.1, random_state: int = 42):
        self.scaler = RobustScaler()  # âœ… ØªØºÙŠÙŠØ± Ù…Ù† StandardScaler Ø¥Ù„Ù‰ RobustScaler
        self.label_encoder = LabelEncoder()
        self.max_timesteps = max_timesteps
        self.test_size = test_size
        self.val_size = val_size
        self.random_state = random_state

    # ======================================================
    # ğŸ§  Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ù† ÙƒÙ„ Ø­Ø±ÙƒØ© (Gesture) - Ù…ÙØ­Ø³Ù‘Ù†
    # ======================================================
    def extract_sequence_features(self, gesture: Dict) -> np.ndarray:
        frames = gesture.get('frames', [])
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„ØµÙŠØºØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        if not frames and 'points' in gesture:
            frames = [{'points': gesture['points'], 'delta_ms': gesture.get('delta_ms', 16)}]  # 16ms Ø§ÙØªØ±Ø§Ø¶ÙŠ

        if not frames:
            return None

        sequence = []
        prev_points = None

        for i, frame in enumerate(frames):
            points = frame.get('points', [])
            if not points:
                continue

            delta_ms = max(frame.get('delta_ms', 16), 1)  # âœ… ØªØ¬Ù†Ø¨ Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ±
            delta_s = delta_ms / 1000.0

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            x = np.array([p.get('x', 0) for p in points])
            y = np.array([p.get('y', 0) for p in points])
            pressure = np.array([p.get('pressure', 0.5) for p in points])  # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© 0.5
            angle = np.array([p.get('angle', 0) for p in points])

            # âœ… Ø­Ø³Ø§Ø¨ Ø§Ù„Ø³Ø±Ø¹Ø© ÙˆØ§Ù„ØªØ³Ø§Ø±Ø¹ Ø¨Ø´ÙƒÙ„ Ø£ÙƒØ«Ø± Ø¯Ù‚Ø©
            if i == 0 or prev_points is None:
                # Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø£ÙˆÙ„ - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚ÙŠÙ… ØµÙØ±ÙŠØ©
                vx = np.zeros_like(x)
                vy = np.zeros_like(y)
                ax = np.zeros_like(x)
                ay = np.zeros_like(y)
            else:
                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø³Ø±Ø¹Ø© Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„ØªØºÙŠØ± ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹
                prev_x = np.array([p.get('x', 0) for p in prev_points])
                prev_y = np.array([p.get('y', 0) for p in prev_points])
                
                dx = x - prev_x
                dy = y - prev_y
                
                vx = dx / delta_s
                vy = dy / delta_s
                
                # âœ… ØªØ­Ø³ÙŠÙ† Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ³Ø§Ø±Ø¹
                if i == 1:
                    ax = np.zeros_like(vx)
                    ay = np.zeros_like(vy)
                else:
                    # Ù†Ø­ØªØ§Ø¬ Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø³Ø±Ø¹Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
                    prev_prev_points = frames[i-2].get('points', [])
                    if prev_prev_points:
                        prev_prev_x = np.array([p.get('x', 0) for p in prev_prev_points])
                        prev_prev_y = np.array([p.get('y', 0) for p in prev_prev_points])
                        prev_delta_ms = max(frames[i-1].get('delta_ms', 16), 1)
                        prev_delta_s = prev_delta_ms / 1000.0
                        
                        prev_dx = prev_x - prev_prev_x
                        prev_dy = prev_y - prev_prev_y
                        prev_vx = prev_dx / prev_delta_s
                        prev_vy = prev_dy / prev_delta_s
                        
                        ax = (vx - prev_vx) / delta_s
                        ay = (vy - prev_vy) / delta_s
                    else:
                        ax = np.zeros_like(vx)
                        ay = np.zeros_like(vy)

            # magnitude Ù…Ø­Ø³ÙˆØ¨ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
            velocity_magnitude = np.sqrt(vx**2 + vy**2)
            acceleration_magnitude = np.sqrt(ax**2 + ay**2)

            # âœ… Ù…ÙŠØ²Ø§Øª Ù…Ø­Ø³Ù†Ø© Ù…Ø¹ Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¢Ù…Ù†Ø©
            frame_features = [
                np.mean(x) if len(x) > 0 else 0.0,
                np.std(x) if len(x) > 0 else 0.1,
                np.mean(y) if len(y) > 0 else 0.0,
                np.std(y) if len(y) > 0 else 0.1,
                np.mean(pressure) if len(pressure) > 0 else 0.5,
                np.std(pressure) if len(pressure) > 0 else 0.1,
                np.mean(angle) if len(angle) > 0 else 0.0,
                np.std(angle) if len(angle) > 0 else 0.1,
                np.mean(vx) if len(vx) > 0 else 0.0,
                np.std(vx) if len(vx) > 0 else 0.1,
                np.mean(vy) if len(vy) > 0 else 0.0,
                np.std(vy) if len(vy) > 0 else 0.1,
                np.mean(ax) if len(ax) > 0 else 0.0,
                np.std(ax) if len(ax) > 0 else 0.1,
                np.mean(ay) if len(ay) > 0 else 0.0,
                np.std(ay) if len(ay) > 0 else 0.1,
                np.mean(velocity_magnitude) if len(velocity_magnitude) > 0 else 0.0,
                np.std(velocity_magnitude) if len(velocity_magnitude) > 0 else 0.1,
                np.mean(acceleration_magnitude) if len(acceleration_magnitude) > 0 else 0.0,
                delta_s,
                len(points)
            ]
            
            sequence.append(frame_features)
            prev_points = points  # Ø­ÙØ¸ Ø§Ù„Ù†Ù‚Ø§Ø· Ù„Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©

        if not sequence:
            return None

        # âœ… ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø·ÙˆÙ„ Ù…Ø¹ Ø­Ø´Ùˆ Ø°ÙƒÙŠ (Ù„Ø§ Ø£ØµÙØ§Ø±)
        feature_dim = len(sequence[0])
        if len(sequence) < self.max_timesteps:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„Ù„Ø­Ø´Ùˆ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø£ØµÙØ§Ø±
            last_frame = sequence[-1]
            padding_frames = [last_frame] * (self.max_timesteps - len(sequence))
            sequence.extend(padding_frames)
        else:
            sequence = sequence[:self.max_timesteps]

        return np.array(sequence)

    # ======================================================
    # ğŸ”„ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª + Ø§Ù„Ø³ÙƒØ§ÙŠÙ„ + Ø§Ù„ØªØ´ÙÙŠØ± - Ù…ÙØ­Ø³Ù‘Ù†
    # ======================================================
    def split_data(self, gestures_data: List[Dict], fixed_indices=None):
        features, labels = [], []
        
        print(f"ğŸ” Processing {len(gestures_data)} gestures...")
        
        for i, gesture in enumerate(gestures_data):
            seq = self.extract_sequence_features(gesture)
            if seq is not None:
                features.append(seq)
                labels.append(gesture['character'])
            else:
                print(f"âš ï¸ Skipped gesture {i} due to missing data")

        if len(features) == 0:
            raise ValueError("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨.")

        X = np.array(features)
        y = np.array(labels)

        print(f"âœ… Extracted {len(X)} sequences with shape {X.shape}")

        # âœ… ÙØ­Øµ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªØ³Ù…ÙŠØ§Øª
        unique_labels, counts = np.unique(y, return_counts=True)
        print(f"ğŸ“Š Label distribution: {dict(zip(unique_labels, counts))}")

        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if fixed_indices:
            X_train = X[fixed_indices['train']]
            X_val = X[fixed_indices['val']]
            X_test = X[fixed_indices['test']]
            y_train = y[fixed_indices['train']]
            y_val = y[fixed_indices['val']]
            y_test = y[fixed_indices['test']]
        else:
            stratify_labels = y if len(np.unique(y)) > 1 else None
            X_temp, X_test, y_temp, y_test = train_test_split(
                X, y, test_size=self.test_size,
                stratify=stratify_labels, random_state=self.random_state
            )

            val_size_adj = self.val_size / (1 - self.test_size)
            stratify_temp = y_temp if len(np.unique(y_temp)) > 1 else None
            X_train, X_val, y_train, y_val = train_test_split(
                X_temp, y_temp, test_size=val_size_adj,
                stratify=stratify_temp, random_state=self.random_state
            )

        print(f"ğŸ“ Split sizes - Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}")

        # ======================================================
        # âœ… Robust Scaling Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙ‚Ø·
        # ======================================================
        n_features = X_train.shape[2]
        
        print("ğŸ”§ Applying RobustScaler...")
        X_train_flat = X_train.reshape(-1, n_features)
        self.scaler.fit(X_train_flat)

        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¹Ø§ÙŠØ±Ø©
        X_train_scaled = self.scaler.transform(X_train_flat).reshape(X_train.shape)
        X_val_scaled = self.scaler.transform(X_val.reshape(-1, n_features)).reshape(X_val.shape)
        X_test_scaled = self.scaler.transform(X_test.reshape(-1, n_features)).reshape(X_test.shape)

        # âœ… ÙØ­Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§ÙŠØ±Ø©
        print(f"ğŸ“Š After scaling - Train range: [{X_train_scaled.min():.2f}, {X_train_scaled.max():.2f}]")
        print(f"ğŸ“Š After scaling - Mean: {X_train_scaled.mean():.2f}, Std: {X_train_scaled.std():.2f}")

        # ======================================================
        # âœ… Label Encoding Ù…Ø­Ø³Ù‘Ù†
        # ======================================================
        self.label_encoder.fit(y_train)
        y_train_enc = self.label_encoder.transform(y_train)

        print(f"ğŸ¯ Label classes: {self.label_encoder.classes_}")

        def safe_encode(y_vals):
            encoded = []
            for lbl in y_vals:
                if lbl in self.label_encoder.classes_:
                    encoded.append(self.label_encoder.transform([lbl])[0])
                else:
                    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØµÙ†Ù Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹ ÙƒØ¨Ø¯ÙŠÙ„
                    encoded.append(0)  # Ø£Ùˆ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… np.argmax(np.bincount(y_train_enc))
            return np.array(encoded)

        y_val_enc = safe_encode(y_val)
        y_test_enc = safe_encode(y_test)

        # ======================================================
        # ğŸ§¾ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙ‚Ø³ÙŠÙ… Ù…ÙØµÙ„Ø©
        # ======================================================
        split_info = {
            "train_samples": len(y_train_enc),
            "val_samples": len(y_val_enc),
            "test_samples": len(y_test_enc),
            "train_distribution": dict(zip(*np.unique(y_train_enc, return_counts=True))),
            "val_distribution": dict(zip(*np.unique(y_val_enc, return_counts=True))),
            "test_distribution": dict(zip(*np.unique(y_test_enc, return_counts=True))),
            "feature_range_after_scaling": {
                "min": float(X_train_scaled.min()),
                "max": float(X_train_scaled.max()),
                "mean": float(X_train_scaled.mean()),
                "std": float(X_train_scaled.std())
            }
        }

        print("âœ… Data splitting and preprocessing completed successfully!")
        return X_train_scaled, X_val_scaled, X_test_scaled, y_train_enc, y_val_enc, y_test_enc, split_info, fixed_indices

    # ======================================================
    # ğŸ“ˆ Ø­ÙØ¸ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ÙŠØ²Ø§Øª - Ù…ÙØ­Ø³Ù‘Ù†
    # ======================================================
    def plot_feature_distribution(self, gestures_data: List[Dict]):
        features_to_save = ['x', 'y', 'pressure', 'angle', 'delta_ms']
        agg = {}

        print(f"ğŸ“ˆ Analyzing feature distribution for {len(gestures_data)} gestures...")

        for gesture in gestures_data:
            char = gesture['character']
            if char not in agg:
                agg[char] = {feat: [] for feat in features_to_save}

            frames = gesture.get('frames', [])
            if not frames and 'points' in gesture:
                frames = [{'points': gesture['points'], 'delta_ms': gesture.get('delta_ms', 16)}]

            for frame in frames:
                points = frame.get('points', [])
                delta_ms = max(frame.get('delta_ms', 16), 1)
                
                if not points:
                    agg[char]['delta_ms'].append(delta_ms)
                    continue

                for feat in features_to_save:
                    if feat == 'delta_ms':
                        agg[char]['delta_ms'].append(delta_ms)
                    else:
                        values = [p.get(feat, 0) for p in points]
                        agg[char][feat].extend(values)

        rows = []
        for char, feats in agg.items():
            row = {'character': char, 'total_samples': sum(len(v) for v in feats.values())}
            for feat, values in feats.items():
                arr = np.array(values)
                if arr.size == 0:
                    row.update({
                        f'{feat}_mean': 0.0,
                        f'{feat}_std': 0.0,
                        f'{feat}_min': 0.0,
                        f'{feat}_max': 0.0,
                        f'{feat}_nonzero_count': 0
                    })
                else:
                    non_zero = arr[arr != 0]
                    row.update({
                        f'{feat}_mean': float(np.mean(arr)),
                        f'{feat}_std': float(np.std(arr)),
                        f'{feat}_min': float(np.min(arr)),
                        f'{feat}_max': float(np.max(arr)),
                        f'{feat}_nonzero_count': len(non_zero)
                    })
            rows.append(row)

        df = pd.DataFrame(rows)
        df.to_csv("gesture_features_analysis.csv", index=False, encoding='utf-8-sig')
        print("âœ… Gesture features analysis saved to gesture_features_analysis.csv")
        
        # Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø³Ø±ÙŠØ¹
        print("\nğŸ“Š Feature Analysis Summary:")
        print(df[['character', 'total_samples', 'x_mean', 'y_mean', 'pressure_mean']].to_string(index=False))
        
        return df