import numpy as np
from keras.models import load_model, Model
from typing import cast
from app.services.feature_extractor import GestureFeatureExtractor
import os


class PredictionPipeline:
    def __init__(self, model_path=None, label_path=None, verbose=False):
        self.verbose = verbose

        # Ù…Ø³Ø§Ø±Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        model_dir = "ai_model"
        if model_path is None:
            model_path = os.path.join(model_dir, "best_model.h5")
        if label_path is None:
            label_path = os.path.join(model_dir, "label_classes.npy")

        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model file not found: {model_path}")
        if not os.path.exists(label_path):
            raise FileNotFoundError(f"Label classes file not found: {label_path}")

        if self.verbose:
            print(f"ğŸ“‚ Loading model: {model_path}")
            print(f"ğŸ“‚ Loading labels: {label_path}")

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        self.model = cast(Model, load_model(model_path))
        if self.model is None:
            raise RuntimeError(f"Failed to load model from: {model_path}")

        # ØªØ­Ù…ÙŠÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£ØµÙ†Ø§Ù
        self.class_labels = np.load(label_path, allow_pickle=True).tolist()

        # Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª
        self.extractor = GestureFeatureExtractor(
            image_size=64,
            thickness=1.5,
            channels=("stroke", "velocity")
        )

        if self.verbose:
            print(f"âœ… Model loaded. Classes: {len(self.class_labels)}")

    # -----------------------------------------------------
    def gesture_to_image(self, gesture_dict):
        frames = gesture_dict.get("frames", [])
        points = []

        # Ø¬Ù…Ø¹ Ø§Ù„Ù†Ù‚Ø§Ø·
        for frame in frames:
            points.extend(frame.get("points", []))

        if not points:
            raise ValueError("No valid points in gesture.")

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØµÙˆØ±Ø© = (64,64,2)
        img = self.extractor.extract_features(points, as_image=True)

        # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø¥Ù„Ù‰ Ù‚Ù†Ø§Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· (64,64,1)
        if img.ndim == 3 and img.shape[-1] == 2:
            img = img[..., :1]

        # Ø¥Ø¶Ø§ÙØ© batch dimension
        return np.expand_dims(img, axis=0)

    # -----------------------------------------------------
    def predict_gesture_top3(self, gesture_dict):
        img = self.gesture_to_image(gesture_dict)

        # ØªÙ†Ø¨Ø¤
        pred_probs = self.model.predict(img)[0]

        # Ø£ÙØ¶Ù„ 3
        top3_idx = np.argsort(pred_probs)[::-1][:3]
        top3_chars = [self.class_labels[i] for i in top3_idx]
        top3_conf = [float(pred_probs[i]) for i in top3_idx]

        return {
            "predicted_char": top3_chars[0],
            "confidence": top3_conf[0],
            "top3": [
                {"char": c, "confidence": p}
                for c, p in zip(top3_chars, top3_conf)
            ],
        }

    # -----------------------------------------------------
    def get_model_info(self):
        return {
            "input_shape": self.model.input_shape,
            "output_shape": self.model.output_shape,
            "num_classes": len(self.class_labels),
        }
